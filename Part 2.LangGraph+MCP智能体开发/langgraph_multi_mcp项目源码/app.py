import streamlit as st
import asyncio
import nest_asyncio
import json
import os
import platform
# ----- 1. é¡µé¢å’ŒCSSç¾åŒ– -----

if platform.system() == "Windows":
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())

# Apply nest_asyncio: Allow nested calls within an already running event loop
nest_asyncio.apply()

# Create and reuse global event loop (create once and continue using)
if "event_loop" not in st.session_state:
    loop = asyncio.new_event_loop()
    st.session_state.event_loop = loop
    asyncio.set_event_loop(loop)

from langgraph.prebuilt import create_react_agent
from langchain_core.messages import HumanMessage
from dotenv import load_dotenv
from langchain_mcp_adapters.client import MultiServerMCPClient
from utils import astream_graph, random_uuid
from langchain_core.messages.ai import AIMessageChunk
from langchain_core.messages.tool import ToolMessage
from langgraph.checkpoint.memory import MemorySaver
from langchain_core.runnables import RunnableConfig
from langchain_deepseek import ChatDeepSeek

# Load environment variables (get API keys and settings from .env file)
load_dotenv(override=True)

# config.json file path setting
CONFIG_FILE_PATH = "config.json"


# ä» JSON æ–‡ä»¶ä¸­åŠ è½½è®¾ç½®
def load_config_from_json():
    """
    Loads settings from config.json file.
    Creates a file with default settings if it doesn't exist.

    Returns:
        dict: Loaded settings
    """
    default_config = {
        "get_current_time": {
            "command": "python",
            "args": ["./mcp_server_time.py"],
            "transport": "stdio"
        }
    }
    
    try:
        if os.path.exists(CONFIG_FILE_PATH):
            with open(CONFIG_FILE_PATH, "r", encoding="utf-8") as f:
                return json.load(f)
        else:
            # Create file with default settings if it doesn't exist
            save_config_to_json(default_config)
            return default_config
    except Exception as e:
        st.error(f"Error loading settings file: {str(e)}")
        return default_config

# å°†è®¾ç½®ä¿å­˜åˆ° JSON æ–‡ä»¶
def save_config_to_json(config):
    """
    Saves settings to config.json file.

    Args:
        config (dict): Settings to save
    
    Returns:
        bool: Save success status
    """
    try:
        with open(CONFIG_FILE_PATH, "w", encoding="utf-8") as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        return True
    except Exception as e:
        st.error(f"Error saving settings file: {str(e)}")
        return False

# åˆå§‹åŒ–ç™»å½• session å˜é‡
if "authenticated" not in st.session_state:
    st.session_state.authenticated = False

# æ£€æŸ¥æ˜¯å¦éœ€è¦ç™»å½•
use_login = os.environ.get("USE_LOGIN", "false").lower() == "true"

# æ ¹æ®ç™»å½•çŠ¶æ€æ›´æ”¹é¡µé¢è®¾ç½®
if use_login and not st.session_state.authenticated:
    # ç™»å½•é¡µé¢ä½¿ç”¨é»˜è®¤ï¼ˆçª„ï¼‰å¸ƒå±€
    st.set_page_config(page_title="LangGraph Agent MCP Tools", page_icon="ğŸ§ ")
else:
    # ä¸»åº”ç”¨ä½¿ç”¨å®½å¸ƒå±€
    st.set_page_config(page_title="LangGraph Agent MCP Tools", page_icon="ğŸ§ ", layout="wide")


# ç™»å½•é¡µé¢CSSç¾åŒ–
def inject_css():
    st.markdown("""
        <style>
        /* èƒŒæ™¯æ¸å˜ */
        body {
            background: linear-gradient(120deg, #f8fafc 0%, #dbeafe 100%) !important;
        }
        .main {
            background-color: rgba(255,255,255,0.95);
            border-radius: 24px;
            box-shadow: 0 4px 32px rgba(30, 64, 175, 0.10);
            padding: 2.5em 2em 2em 2em;
            max-width: 380px;
            margin: 3em auto 0 auto;
        }
        header, .st-emotion-cache-1avcm0n {display: none !important;}

        .stTextInput>div>div>input {
            border-radius: 1em;
            padding: 0.6em 0.9em;
        }
        .login-logo {
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 1.2em;
        }
        .login-logo img {
            height: 48px;
            margin-right: 12px;
        }
        .login-tip {
            color: #64748b;
            margin-bottom: 1.5em;
            font-size: 1.05em;
            text-align: center;
        }
                
        /* è®©æŒ‰é’®è‡ªé€‚åº”å®½åº¦ï¼Œå¹¶å±…ä¸­æ˜¾ç¤º */
        .stForm .stButton {
            display: flex;
            justify-content: center;
        }

        .stButton > button {
            width: 140px !important;     /* è‡ªå·±è®¾å®½åº¦ï¼Œæ¯”å¦‚140pxï¼Œä¹Ÿå¯ä»¥80%ã€fit-contentç­‰ */
            margin: 0 auto;
        }

        </style>
    """, unsafe_allow_html=True)

inject_css()

# ----- 2. ç™»å½•é€»è¾‘ -----
use_login = True  # æŒ‰éœ€è®¾ç½®

if use_login and not st.session_state.get("authenticated", False):
    with st.container():
        # logoå’Œæ ‡é¢˜
        st.markdown("""
        <div class="login-logo">
            <img src="https://img.icons8.com/ios-filled/50/lock-2.png"/>
            <span style="font-size:1.6em;font-weight:700;">LangGraph MCP by ä¹å¤©Hector</span>
        </div>
        """, unsafe_allow_html=True)

        st.markdown('<div class="login-tip">è¯·è¾“å…¥ç”¨æˆ·åå’Œå¯†ç ä»¥è¿›å…¥ç³»ç»Ÿã€‚</div>', unsafe_allow_html=True)

        # è¡¨å•
        with st.form("login_form"):
            username = st.text_input("ç”¨æˆ·å", placeholder="è¾“å…¥æ‚¨çš„ç”¨æˆ·å")
            password = st.text_input("å¯†ç ", type="password", placeholder="è¾“å…¥æ‚¨çš„å¯†ç ")
            submit_button = st.form_submit_button("ç™»å½•")

            if submit_button:
                expected_username = os.environ.get("USER_ID")
                expected_password = os.environ.get("USER_PASSWORD")
                if username == expected_username and password == expected_password:
                    st.session_state.authenticated = True
                    st.success("âœ… ç™»å½•æˆåŠŸï¼è¯·ç¨å€™è‡ªåŠ¨è¿›å…¥ä¸»é¡µ...")
                else:
                    st.error("âŒ ç”¨æˆ·åæˆ–å¯†ç ä¸æ­£ç¡®ï¼Œè¯·é‡è¯•ã€‚")

        st.markdown('</div>', unsafe_allow_html=True)
    st.stop()


st.sidebar.divider()  

# å·²ç™»å½•é¡µé¢æ ‡é¢˜å’Œæè¿°
st.title("ğŸ’¬ LangGraph MCP by ä¹å¤©Hector")
st.markdown("âœ¨ å¯ä»¥è‡ªå®šä¹‰æ¥å…¥å’Œä½¿ç”¨MCPå·¥å…·çš„ReActä»£ç†")


# è®¾ç½®ç³»ç»Ÿæç¤ºè¯
SYSTEM_PROMPT = """<ROLE>
You are a smart agent with an ability to use tools. 
You will be given a question and you will use the tools to answer the question.
Pick the most relevant tool to answer the question. 
If you are failed to answer the question, try different tools to get context.
Your answer should be very polite and professional.
</ROLE>

----

<INSTRUCTIONS>
Step 1: Analyze the question
- Analyze user's question and final goal.
- If the user's question is consist of multiple sub-questions, split them into smaller sub-questions.

Step 2: Pick the most relevant tool
- Pick the most relevant tool to answer the question.
- If you are failed to answer the question, try different tools to get context.

Step 3: Answer the question
- Answer the question in the same language as the question.
- Your answer should be very polite and professional.

Step 4: Provide the source of the answer(if applicable)
- If you've used the tool, provide the source of the answer.
- Valid sources are either a website(URL) or a document(PDF, etc).

Guidelines:
- If you've used the tool, your answer should be based on the tool's output(tool's output is more important than your own knowledge).
- If you've used the tool, and the source is valid URL, provide the source(URL) of the answer.
- Skip providing the source if the source is not URL.
- Answer in the same language as the question.
- Answer should be concise and to the point.
- Avoid response your output with any other information than the answer and the source.  
</INSTRUCTIONS>

----

<OUTPUT_FORMAT>
(concise answer to the question)

**Source**(if applicable)
- (source1: valid URL)
- (source2: valid URL)
- ...
</OUTPUT_FORMAT>
"""


# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
if "session_initialized" not in st.session_state:
    st.session_state.session_initialized = False  
    st.session_state.agent = None  
    st.session_state.history = []  
    st.session_state.mcp_client = None  
    st.session_state.timeout_seconds = (
        120  
    )
    st.session_state.selected_model = (
        "deepseek-chat"   # é»˜è®¤çš„æ¨¡å‹æ˜¯ DeepSeek v3
    )
    st.session_state.recursion_limit = 100  # é€’å½’è°ƒç”¨é™åˆ¶ï¼Œé»˜è®¤100

if "thread_id" not in st.session_state:
    st.session_state.thread_id = random_uuid()


# --- å·¥å…·å‡½æ•°å®šä¹‰ ---
async def cleanup_mcp_client():
    """
    Safely terminates the existing MCP client.

    Properly releases resources if an existing client exists.
    """
    if "mcp_client" in st.session_state and st.session_state.mcp_client is not None:
        try:
            # æ–°ç‰ˆæœ¬ä¸éœ€è¦æ‰‹åŠ¨è°ƒç”¨__aexit__ï¼Œç›´æ¥è®¾ç½®ä¸ºNoneå³å¯
            st.session_state.mcp_client = None
        except Exception as e:
            import traceback
            st.error(f"æ¸…ç†MCPå®¢æˆ·ç«¯æ—¶å‡ºé”™: {str(e)}")
            st.session_state.mcp_client = None

def print_message():
    """
    Displays chat history on the screen.

    Distinguishes between user and assistant messages on the screen,
    and displays tool call information within the assistant message container.
    """
    i = 0
    while i < len(st.session_state.history):
        message = st.session_state.history[i]
        if message["role"] == "user":
            st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»").markdown(message["content"])
            i += 1
        elif message["role"] == "assistant":
            # åˆ›å»ºåŠ©æ‰‹æ¶ˆæ¯å®¹å™¨
            with st.chat_message("assistant", avatar="ğŸ¤–"):
                # æ˜¾ç¤ºåŠ©æ‰‹æ¶ˆæ¯å†…å®¹
                st.markdown(message["content"])

                # æ£€æŸ¥ä¸‹ä¸€ä¸ªæ¶ˆæ¯æ˜¯å¦æ˜¯å·¥å…·è°ƒç”¨ä¿¡æ¯
                if (
                    i + 1 < len(st.session_state.history)
                    and st.session_state.history[i + 1]["role"] == "assistant_tool"
                ):
                    # åœ¨åŒä¸€ä¸ªå®¹å™¨ä¸­æ˜¾ç¤ºå·¥å…·è°ƒç”¨ä¿¡æ¯
                    with st.expander("ğŸ”§ Tool Call Information", expanded=False):
                        st.markdown(st.session_state.history[i + 1]["content"])
                    i += 2  # é€’å¢2ï¼Œå› ä¸ºæˆ‘ä»¬å¤„ç†äº†ä¸¤ä¸ªæ¶ˆæ¯
                else:
                    i += 1  # é€’å¢1ï¼Œå› ä¸ºæˆ‘ä»¬åªå¤„ç†äº†ä¸€ä¸ªå¸¸è§„æ¶ˆæ¯
        else:
            # è·³è¿‡åŠ©æ‰‹å·¥å…·æ¶ˆæ¯ï¼Œå› ä¸ºå®ƒä»¬å·²ç»åœ¨ä¸Šé¢å¤„ç†äº†
            i += 1


def get_streaming_callback(text_placeholder, tool_placeholder):
    """
    Creates a streaming callback function.

    This function creates a callback function to display responses generated from the LLM in real-time.
    It displays text responses and tool call information in separate areas.

    Args:
        text_placeholder: Streamlit component to display text responses
        tool_placeholder: Streamlit component to display tool call information

    Returns:
        callback_func: Streaming callback function
        accumulated_text: List to store accumulated text responses
        accumulated_tool: List to store accumulated tool call information
    """
    accumulated_text = []
    accumulated_tool = []

    def callback_func(message: dict):
        nonlocal accumulated_text, accumulated_tool
        message_content = message.get("content", None)

        if isinstance(message_content, AIMessageChunk):
            content = message_content.content
            if (
                hasattr(message_content, "tool_calls")
                and message_content.tool_calls
                and len(message_content.tool_calls[0]["name"]) > 0
            ):
                tool_call_info = message_content.tool_calls[0]
                accumulated_tool.append("\n```json\n" + str(tool_call_info) + "\n```\n")
                with tool_placeholder.expander(
                    "ğŸ”§ Tool Call Information", expanded=True
                ):
                    st.markdown("".join(accumulated_tool))
            # å¦‚æœå†…å®¹æ˜¯å­—ç¬¦ä¸²ç±»å‹
            elif isinstance(content, str):
                accumulated_text.append(content)
                text_placeholder.markdown("".join(accumulated_text))
            # å¦‚æœå­˜åœ¨æ— æ•ˆçš„å·¥å…·è°ƒç”¨ä¿¡æ¯
            elif (
                hasattr(message_content, "invalid_tool_calls")
                and message_content.invalid_tool_calls
            ):
                tool_call_info = message_content.invalid_tool_calls[0]
                accumulated_tool.append("\n```json\n" + str(tool_call_info) + "\n```\n")
                with tool_placeholder.expander(
                    "ğŸ”§ Tool Call Information (Invalid)", expanded=True
                ):
                    st.markdown("".join(accumulated_tool))
            # å¦‚æœtool_call_chunkså±æ€§å­˜åœ¨
            elif (
                hasattr(message_content, "tool_call_chunks")
                and message_content.tool_call_chunks
            ):
                tool_call_chunk = message_content.tool_call_chunks[0]
                accumulated_tool.append(
                    "\n```json\n" + str(tool_call_chunk) + "\n```\n"
                )
                with tool_placeholder.expander(
                    "ğŸ”§ Tool Call Information", expanded=True
                ):
                    st.markdown("".join(accumulated_tool))
            # å¦‚æœtool_callså­˜åœ¨additional_kwargsä¸­ï¼ˆæ”¯æŒå„ç§æ¨¡å‹å…¼å®¹æ€§ï¼‰
            elif (
                hasattr(message_content, "additional_kwargs")
                and "tool_calls" in message_content.additional_kwargs
            ):
                tool_call_info = message_content.additional_kwargs["tool_calls"][0]
                accumulated_tool.append("\n```json\n" + str(tool_call_info) + "\n```\n")
                with tool_placeholder.expander(
                    "ğŸ”§ Tool Call Information", expanded=True
                ):
                    st.markdown("".join(accumulated_tool))
        # å¦‚æœæ¶ˆæ¯æ˜¯å·¥å…·æ¶ˆæ¯ï¼ˆå·¥å…·å“åº”ï¼‰
        elif isinstance(message_content, ToolMessage):
            accumulated_tool.append(
                "\n```json\n" + str(message_content.content) + "\n```\n"
            )
            with tool_placeholder.expander("ğŸ”§ Tool Call Information", expanded=True):
                st.markdown("".join(accumulated_tool))
        return None
    return callback_func, accumulated_text, accumulated_tool


async def process_query(query, text_placeholder, tool_placeholder, timeout_seconds=60):
    """
    Processes user questions and generates responses.

    This function passes the user's question to the agent and streams the response in real-time.
    Returns a timeout error if the response is not completed within the specified time.

    Args:
        query: Text of the question entered by the user
        text_placeholder: Streamlit component to display text responses
        tool_placeholder: Streamlit component to display tool call information
        timeout_seconds: Response generation time limit (seconds)

    Returns:
        response: Agent's response object
        final_text: Final text response
        final_tool: Final tool call information
    """
    try:
        if st.session_state.agent:
            streaming_callback, accumulated_text_obj, accumulated_tool_obj = (
                get_streaming_callback(text_placeholder, tool_placeholder)
            )
            try:
                response = await asyncio.wait_for(
                    astream_graph(
                        st.session_state.agent,
                        {"messages": [HumanMessage(content=query)]},
                        callback=streaming_callback,
                        config=RunnableConfig(
                            recursion_limit=st.session_state.recursion_limit,
                            thread_id=st.session_state.thread_id,
                        ),
                    ),
                    timeout=timeout_seconds,
                )
            except asyncio.TimeoutError:
                error_msg = f"â±ï¸ è¯·æ±‚æ—¶é—´è¶…è¿‡ {timeout_seconds} ç§’. è¯·ç¨åå†è¯•."
                return {"error": error_msg}, error_msg, ""

            final_text = "".join(accumulated_text_obj)
            final_tool = "".join(accumulated_tool_obj)
            return response, final_text, final_tool
        else:
            return (
                {"error": "ğŸš« ä»£ç†æœªåˆå§‹åŒ–."},
                "ğŸš« ä»£ç†æœªåˆå§‹åŒ–.",
                "",
            )
    except Exception as e:
        import traceback

        error_msg = f"âŒ æŸ¥è¯¢å¤„ç†æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}\n{traceback.format_exc()}"
        return {"error": error_msg}, error_msg, ""


async def initialize_session(mcp_config=None):
    """
    Initializes MCP session and agent.

    Args:
        mcp_config: MCP tool configuration information (JSON). Uses default settings if None

    Returns:
        bool: Initialization success status
    """
    with st.spinner("ğŸ”„ è¿æ¥åˆ°MCPæœåŠ¡å™¨..."):
        # é¦–å…ˆå®‰å…¨åœ°æ¸…ç†ç°æœ‰çš„å®¢æˆ·ç«¯
        await cleanup_mcp_client()

        if mcp_config is None:
            # ä»config.jsonæ–‡ä»¶åŠ è½½è®¾ç½®
            mcp_config = load_config_from_json()
        
        try:
            # ä½¿ç”¨æ–°çš„APIæ–¹å¼åˆ›å»ºå®¢æˆ·ç«¯
            client = MultiServerMCPClient(mcp_config)
            
            # æ–¹æ³•1: ç›´æ¥è·å–å·¥å…·
            tools = await client.get_tools()
            st.session_state.tool_count = len(tools)
            st.session_state.mcp_client = client

            # æ ¹æ®é€‰æ‹©åˆå§‹åŒ–é€‚å½“çš„æ¨¡å‹
            selected_model = st.session_state.selected_model

            model = ChatDeepSeek(
                model=selected_model,
                temperature=0.1,

            )
            agent = create_react_agent(
                model,
                tools,
                checkpointer=MemorySaver(),
                prompt=SYSTEM_PROMPT,
            )
            st.session_state.agent = agent
            st.session_state.session_initialized = True
            return True
            
        except Exception as e:
            st.error(f"âŒ MCPå®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {str(e)}")
            st.error("è¯·æ£€æŸ¥MCPæœåŠ¡å™¨é…ç½®æ˜¯å¦æ­£ç¡®")
            return False


# --- Sidebar: ç³»ç»Ÿè®¾ç½® ---
with st.sidebar:
    st.subheader("âš™ï¸ ç³»ç»Ÿè®¾ç½®")

    # æ¨¡å‹é€‰æ‹©åŠŸèƒ½
    # åˆ›å»ºå¯ç”¨æ¨¡å‹çš„åˆ—è¡¨
    available_models = []

    has_deepseek_key = os.environ.get("DEEPSEEK_API_KEY") is not None
    if has_deepseek_key:
        available_models.extend(["deepseek-chat"])

  
    if not available_models:
        st.warning(
            "âš ï¸ API key æ²¡æœ‰é…ç½®. è¯·åœ¨ .env æ–‡ä»¶ä¸­æ·»åŠ  DEEPSEEK_API_KEY."
        )
        available_models = ["deepseek-chat"]

    # æ¨¡å‹é€‰æ‹©ä¸‹æ‹‰æ¡†
    previous_model = st.session_state.selected_model
    st.session_state.selected_model = st.selectbox(
        "ğŸ¤– é€‰æ‹©æ¨¡å‹",
        options=available_models,
        index=(
            available_models.index(st.session_state.selected_model)
            if st.session_state.selected_model in available_models
            else 0
        ),
        help="DeepSeek æ¨¡å‹éœ€è¦ DEEPSEEK_API_KEY ä½œä¸ºç¯å¢ƒå˜é‡.",
    )
    if (
        previous_model != st.session_state.selected_model
        and st.session_state.session_initialized
    ):
        st.warning(
            "âš ï¸ æ¨¡å‹å·²æ›´æ”¹. ç‚¹å‡» 'åº”ç”¨è®¾ç½®' æŒ‰é’®ä»¥åº”ç”¨æ›´æ”¹."
        )

    # æ·»åŠ è¶…æ—¶è®¾ç½®æ»‘å—
    st.session_state.timeout_seconds = st.slider(
        "â±ï¸ å“åº”ç”Ÿæˆæ—¶é—´é™åˆ¶ (ç§’)",
        min_value=60,
        max_value=300,
        value=st.session_state.timeout_seconds,
        step=10,
        help="è®¾ç½®ä»£ç†ç”Ÿæˆå“åº”çš„æœ€å¤§æ—¶é—´. å¤æ‚ä»»åŠ¡å¯èƒ½éœ€è¦æ›´å¤šæ—¶é—´.",
    )

    st.session_state.recursion_limit = st.slider(
        "â±ï¸ é€’å½’è°ƒç”¨é™åˆ¶ (æ¬¡æ•°)",
        min_value=10,
        max_value=200,
        value=st.session_state.recursion_limit,
        step=10,
        help="è®¾ç½®é€’å½’è°ƒç”¨é™åˆ¶. è®¾ç½®è¿‡é«˜çš„å€¼å¯èƒ½ä¼šå¯¼è‡´å†…å­˜é—®é¢˜.",
    )

    st.divider() 

    # å·¥å…·è®¾ç½®éƒ¨åˆ†
    st.subheader("ğŸ”§ å·¥å…·è®¾ç½®")

    # ç®¡ç†æ‰©å±•å™¨çŠ¶æ€
    if "mcp_tools_expander" not in st.session_state:
        st.session_state.mcp_tools_expander = False

    # MCP å·¥å…·æ·»åŠ ç•Œé¢
    with st.expander("ğŸ§° æ·»åŠ  MCP å·¥å…·", expanded=st.session_state.mcp_tools_expander):
        # ä»config.jsonæ–‡ä»¶åŠ è½½è®¾ç½®
        loaded_config = load_config_from_json()
        default_config_text = json.dumps(loaded_config, indent=2, ensure_ascii=False)
        
        # æ ¹æ®ç°æœ‰çš„mcp_config_textåˆ›å»ºpending config
        if "pending_mcp_config" not in st.session_state:
            try:
                st.session_state.pending_mcp_config = loaded_config
            except Exception as e:
                st.error(f"Failed to set initial pending config: {e}")

        # æ·»åŠ å•ä¸ªå·¥å…·çš„UI
        st.subheader("æ·»åŠ å·¥å…·(JSONæ ¼å¼)")
        st.markdown(
            """
        è¯·æ’å…¥ **ä¸€ä¸ªå·¥å…·** åœ¨ JSON æ ¼å¼ä¸­.
        âš ï¸ **é‡è¦**: JSON å¿…é¡»ç”¨èŠ±æ‹¬å· (`{}`) åŒ…è£¹.
        """
        )
        # æä¾›æ›´æ¸…æ™°çš„ç¤ºä¾‹
        example_json = {
            "github": {
                "command": "npx",
                "args": [
                    "-y",
                    "@smithery/cli@latest",
                    "run",
                    "@smithery-ai/github",
                    "--config",
                    '{"githubPersonalAccessToken":"your_token_here"}',
                ],
                "transport": "stdio",
            }
        }

        default_text = json.dumps(example_json, indent=2, ensure_ascii=False)

        new_tool_json = st.text_area(
            "Tool JSON",
            default_text,
            height=250,
        )

        # æ·»åŠ æŒ‰é’®
        if st.button(
            "Add Tool",
            type="primary",
            key="add_tool_button",
            use_container_width=True,
        ):
            try:
                # éªŒè¯è¾“å…¥
                if not new_tool_json.strip().startswith(
                    "{"
                ) or not new_tool_json.strip().endswith("}"):
                    st.error("JSON must start and end with curly braces ({}).")
                    st.markdown('Correct format: `{ "tool_name": { ... } }`')
                else:
                    # è§£æ JSON
                    parsed_tool = json.loads(new_tool_json)

                    # æ£€æŸ¥æ˜¯å¦åœ¨mcpServersæ ¼å¼ä¸­ï¼Œå¹¶ç›¸åº”å¤„ç†
                    if "mcpServers" in parsed_tool:
                        # å°†mcpServersçš„å†…å®¹ç§»åŠ¨åˆ°é¡¶å±‚
                        parsed_tool = parsed_tool["mcpServers"]
                        st.info(
                            "'mcpServers' format detected. Converting automatically."
                        )

                    # æ£€æŸ¥è¾“å…¥çš„å·¥å…·æ•°é‡
                    if len(parsed_tool) == 0:
                        st.error("Please enter at least one tool.")
                    else:
                        # å¤„ç†æ‰€æœ‰å·¥å…·
                        success_tools = []
                        for tool_name, tool_config in parsed_tool.items():
                            # æ£€æŸ¥URLå­—æ®µå¹¶è®¾ç½®transport
                            if "url" in tool_config:
                                # å¦‚æœURLå­˜åœ¨ï¼Œåˆ™è®¾ç½®transportä¸º"sse"
                                tool_config["transport"] = "sse"
                                st.info(
                                    f"URL detected in '{tool_name}' tool, setting transport to 'sse'."
                                )
                            elif "transport" not in tool_config:
                                # å¦‚æœURLä¸å­˜åœ¨ä¸”transportæœªæŒ‡å®šï¼Œåˆ™è®¾ç½®é»˜è®¤å€¼"stdio"
                                tool_config["transport"] = "stdio"

                            # æ£€æŸ¥å¿…éœ€å­—æ®µ
                            if (
                                "command" not in tool_config
                                and "url" not in tool_config
                            ):
                                st.error(
                                    f"'{tool_name}' tool configuration requires either 'command' or 'url' field."
                                )
                            elif "command" in tool_config and "args" not in tool_config:
                                st.error(
                                    f"'{tool_name}' tool configuration requires 'args' field."
                                )
                            elif "command" in tool_config and not isinstance(
                                tool_config["args"], list
                            ):
                                st.error(
                                    f"'args' field in '{tool_name}' tool must be an array ([]) format."
                                )
                            else:
                                # å°†å·¥å…·æ·»åŠ åˆ°pending_mcp_config
                                st.session_state.pending_mcp_config[tool_name] = (
                                    tool_config
                                )
                                success_tools.append(tool_name)

                        # æˆåŠŸæ¶ˆæ¯
                        if success_tools:
                            if len(success_tools) == 1:
                                st.success(
                                    f"{success_tools[0]} å·¥å…·å·²æ·»åŠ . ç‚¹å‡» 'åº”ç”¨è®¾ç½®' æŒ‰é’®ä»¥åº”ç”¨."
                                )
                            else:
                                tool_names = ", ".join(success_tools)
                                st.success(
                                    f"æ€»å…± {len(success_tools)} ä¸ªå·¥å…· ({tool_names}) å·²æ·»åŠ . ç‚¹å‡» 'åº”ç”¨è®¾ç½®' æŒ‰é’®ä»¥åº”ç”¨."
                                )
                            # æ·»åŠ å·¥å…·åæŠ˜å æ‰©å±•å™¨
                            st.session_state.mcp_tools_expander = False
                            st.rerun()

            except json.JSONDecodeError as e:
                st.error(f"JSON è§£æé”™è¯¯: {e}")
                st.markdown(
                    f"""
                **å¦‚ä½•ä¿®å¤**:
                1. æ£€æŸ¥æ‚¨çš„JSONæ ¼å¼æ˜¯å¦æ­£ç¡®.
                2. æ‰€æœ‰é”®å¿…é¡»ç”¨åŒå¼•å·åŒ…è£¹ (").
                3. å­—ç¬¦ä¸²å€¼ä¹Ÿå¿…é¡»ç”¨åŒå¼•å·åŒ…è£¹ (").
                4. åœ¨å­—ç¬¦ä¸²ä¸­ä½¿ç”¨åŒå¼•å·æ—¶ï¼Œå¿…é¡»è½¬ä¹‰ (\").
                """
                )
            except Exception as e:
                st.error(f"å‘ç”Ÿé”™è¯¯: {e}")

    # æ˜¾ç¤ºå·²æ³¨å†Œçš„å·¥å…·åˆ—è¡¨å¹¶æ·»åŠ åˆ é™¤æŒ‰é’®
    with st.expander("ğŸ“‹ å·²æ³¨å†Œçš„å·¥å…·åˆ—è¡¨", expanded=True):
        try:
            pending_config = st.session_state.pending_mcp_config
        except Exception as e:
            st.error("ä¸æ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„MCPå·¥å…·é…ç½®.")
        else:
            # éå†pending configä¸­çš„é”®ï¼ˆå·¥å…·åç§°ï¼‰
            for tool_name in list(pending_config.keys()):
                col1, col2 = st.columns([8, 2])
                col1.markdown(f"- **{tool_name}**")
                if col2.button("Delete", key=f"delete_{tool_name}"):
                    # ä»pending configä¸­åˆ é™¤å·¥å…·ï¼ˆä¸ç«‹å³åº”ç”¨ï¼‰
                    del st.session_state.pending_mcp_config[tool_name]
                    st.success(
                        f"{tool_name} å·¥å…·å·²åˆ é™¤. ç‚¹å‡» 'åº”ç”¨è®¾ç½®' æŒ‰é’®ä»¥åº”ç”¨."
                    )

    st.divider() 

# --- Sidebar: ç³»ç»Ÿä¿¡æ¯å’Œæ“ä½œæŒ‰é’®éƒ¨åˆ† ---
with st.sidebar:
    st.subheader("ğŸ“Š ç³»ç»Ÿä¿¡æ¯")
    st.write(
        f"ğŸ› ï¸ MCP å·¥å…·æ•°é‡: {st.session_state.get('tool_count', 'åˆå§‹åŒ–ä¸­...')}"
    )
    selected_model_name = st.session_state.selected_model
    st.write(f"ğŸ§  å½“å‰æ¨¡å‹: {selected_model_name}")

    # ç§»åŠ¨åº”ç”¨è®¾ç½®æŒ‰é’®
    if st.button(
        "åº”ç”¨è®¾ç½®",
        key="apply_button",
        type="primary",
        use_container_width=True,
    ):
     
        apply_status = st.empty()
        with apply_status.container():
            st.warning("ğŸ”„ åº”ç”¨æ›´æ”¹. è¯·ç¨å€™...")
            progress_bar = st.progress(0)

            # ä¿å­˜è®¾ç½®
            st.session_state.mcp_config_text = json.dumps(
                st.session_state.pending_mcp_config, indent=2, ensure_ascii=False
            )

            # å°†è®¾ç½®ä¿å­˜åˆ°config.jsonæ–‡ä»¶
            save_result = save_config_to_json(st.session_state.pending_mcp_config)
            if not save_result:
                st.error("âŒ ä¿å­˜è®¾ç½®æ–‡ä»¶å¤±è´¥.")
            
            progress_bar.progress(15)

            # å‡†å¤‡ä¼šè¯åˆå§‹åŒ–
            st.session_state.session_initialized = False
            st.session_state.agent = None

            # æ›´æ–°è¿›åº¦
            progress_bar.progress(30)

            # è¿è¡Œåˆå§‹åŒ–
            success = st.session_state.event_loop.run_until_complete(
                initialize_session(st.session_state.pending_mcp_config)
            )

            # æ›´æ–°è¿›åº¦
            progress_bar.progress(100)

            if success:
                st.success("âœ… æ–°è®¾ç½®å·²åº”ç”¨.")
                # æŠ˜å å·¥å…·æ·»åŠ æ‰©å±•å™¨
                if "mcp_tools_expander" in st.session_state:
                    st.session_state.mcp_tools_expander = False
            else:
                st.error("âŒ Failed to apply settings.")

        # åˆ·æ–°é¡µé¢
        st.rerun()

    st.divider() 

    # æ“ä½œæŒ‰é’®éƒ¨åˆ†
    st.subheader("ğŸ”„ æ“ä½œ")

    # é‡ç½®å¯¹è¯æŒ‰é’®
    if st.button("é‡ç½®å¯¹è¯", use_container_width=True, type="primary"):
        # é‡ç½®thread_id
        st.session_state.thread_id = random_uuid()

        # é‡ç½®å¯¹è¯å†å²
        st.session_state.history = []

        # é€šçŸ¥æ¶ˆæ¯
        st.success("âœ… Conversation has been reset.")

        # åˆ·æ–°é¡µé¢
        st.rerun()

    # æ˜¾ç¤ºæ³¨é”€æŒ‰é’®ï¼ˆä»…å½“ç™»å½•åŠŸèƒ½å¯ç”¨æ—¶ï¼‰
    if use_login and st.session_state.authenticated:
        st.divider() 
        if st.button("æ³¨é”€", use_container_width=True, type="secondary"):
            st.session_state.authenticated = False
            st.success("âœ… å·²æ³¨é”€.")
            st.rerun()

# --- Initialize default session (if not initialized) ---
if not st.session_state.session_initialized:
    st.info(
        "MCP æœåŠ¡å™¨å’Œä»£ç†æœªåˆå§‹åŒ–. è¯·ç‚¹å‡»å·¦ä¾§è¾¹æ çš„ 'åº”ç”¨è®¾ç½®' æŒ‰é’®ä»¥åˆå§‹åŒ–."
    )


# --- æ‰“å°å¯¹è¯å†å² ---
print_message()

# --- ç”¨æˆ·è¾“å…¥å’Œå¤„ç† ---
user_query = st.chat_input("ğŸ’¬ Enter your question")
if user_query:
    if st.session_state.session_initialized:
        st.chat_message("user", avatar="ğŸ§‘â€ğŸ’»").markdown(user_query)
        with st.chat_message("assistant", avatar="ğŸ¤–"):
            tool_placeholder = st.empty()
            text_placeholder = st.empty()
            resp, final_text, final_tool = (
                st.session_state.event_loop.run_until_complete(
                    process_query(
                        user_query,
                        text_placeholder,
                        tool_placeholder,
                        st.session_state.timeout_seconds,
                    )
                )
            )
        if "error" in resp:
            st.error(resp["error"])
        else:
            st.session_state.history.append({"role": "user", "content": user_query})
            st.session_state.history.append(
                {"role": "assistant", "content": final_text}
            )
            if final_tool.strip():
                st.session_state.history.append(
                    {"role": "assistant_tool", "content": final_tool}
                )
            st.rerun()
    else:
        st.warning(
            "âš ï¸ MCP æœåŠ¡å™¨å’Œä»£ç†æœªåˆå§‹åŒ–. è¯·ç‚¹å‡»å·¦ä¾§è¾¹æ çš„ 'åº”ç”¨è®¾ç½®' æŒ‰é’®ä»¥åˆå§‹åŒ–."
        )
